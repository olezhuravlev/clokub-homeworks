# Домашнее задание к занятию "14.5 SecurityContext, NetworkPolicies"

## З адача 1:  Рассмотрите пример 14.5/example-security-context.yml

Создайте модуль

```
kubectl apply -f 14.5/example-security-context.yml
```

Проверьте установленные настройки внутри контейнера

```
kubectl logs security-context-demo
uid=1000 gid=3000 groups=3000
```

## Задача 2 (*): Рассмотрите пример 14.5/example-network-policy.yml

Создайте два модуля. Для первого модуля разрешите доступ к внешнему миру
и ко второму контейнеру. Для второго модуля разрешите связь только с
первым контейнером. Проверьте корректность настроек.

--- 

## Решение

### Задача 1: Рассмотрите пример 14.5/example-security-context.yml

Запустим под, который выполнит команду `id` и завершится:
````bash
$ kubectl apply -f example-security-context.yml 
pod/security-context-demo created

$ kubectl get po -n default -o wide            
NAME                                  READY   STATUS             RESTARTS        AGE   IP               NODE    NOMINATED NODE   READINESS GATES
security-context-demo                 0/1     CrashLoopBackOff   1 (5s ago)      10s   10.200.166.143   node1   <none>           <none>
````

Проверим результат выполнения команды `id`:
````bash
$ kubectl logs security-context-demo
uid=1000 gid=3000 groups=3000
````

Как видим, идентификаторы пользователя и группы совпадают с теми, которые мы указали
в [`securityContext`-параметрах](./example-security-context.yml):
````bash
securityContext:
  runAsUser: 1000
  runAsGroup: 3000
````

Удалим под:
````bash
$ kubectl delete po/security-context-demo
pod "security-context-demo" deleted
````

---


### Задача 2 (*): Рассмотрите пример 14.5/example-network-policy.yml

Для экспериментов создадим два одинаковых деплоймента приложений, выводящих страницы "Hello world 1" и "Hello world 2",
находящихся в разных пространствах имён и проверим их доступность извне и внутри кластера.

Создадим деплойменты приложений:
````bash
$ kubectl apply -f infrastructure/playbooks/templates/back-and-front/deploy-frontend-1.yaml
namespace/ns-1 created
deployment.apps/hworld-1 created
service/hw-svc-1 created

$ kubectl apply -f infrastructure/playbooks/templates/back-and-front/deploy-frontend-2.yaml
namespace/ns-2 created
deployment.apps/hworld-2 created
service/hw-svc-2 created

$ kubectl get deploy -A -o wide 
NAMESPACE  NAME       READY   UP-TO-DATE   AVAILABLE  AGE    CONTAINERS   IMAGES                           SELECTOR
ns-1       hworld-1   1/1     1            1          14h    hworld-1     olezhuravlev/hello-world:1.1.0   app=hworld-1
ns-2       hworld-2   1/1     1            1          14h    hworld-2     olezhuravlev/hello-world:1.2.0   app=hworld-2
...

$ kubectl get svc -A -o wide
NAMESPACE    NAME       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE   SELECTOR
ns-1         hw-svc-1   NodePort    10.32.251.188   <none>        8081:30001/TCP   14h   app=hworld-1
ns-2         hw-svc-2   NodePort    10.32.236.250   <none>        8082:30002/TCP   14h   app=hworld-2
...

$ kubectl get po -A -o wide
NAME                        READY   STATUS    RESTARTS      AGE   IP               NODE    NOMINATED NODE   READINESS GATES
hworld-1-7b949c97f9-8tzjg   1/1     Running   1 (20m ago)   14h   10.200.104.36    node2   <none>           <none>
hworld-2-79f9bbdc9-dqvwc    1/1     Running   1 (20m ago)   14h   10.200.166.161   node1   <none>           <none>
...
````

Для удобства работы пробросим порты на `localhost`:
````bash
$ kubectl port-forward svc/hw-svc-1 -n ns-1 8081:8081
Forwarding from 127.0.0.1:8081 -> 80
Forwarding from [::1]:8081 -> 80
Handling connection for 8081
...
$ kubectl port-forward svc/hw-svc-2 -n ns-1 8082:8082
Forwarding from 127.0.0.1:8082 -> 80
Forwarding from [::1]:8082 -> 80
...
````

Сейчас поды доступны изнутри и снаружи кластера, в чём можно убедиться, получив содержимое веб-страниц как из браузера
на `localhost`, так и с помощью утилиты `curl` из самих подов: 

|                  |                                Hello world 1                               |                                Hello world 2                               |
|:-----------------|:--------------------------------------------------------------------------:|:--------------------------------------------------------------------------:|
| Через внешний IP |          ![hw1_30001_reached.png](images%2Fhw1_30001_reached.png)          |          ![hw2_30002_reached.png](images%2Fhw2_30002_reached.png)          |
| Через localhost  |           ![hw1_8081_reached.png](images%2Fhw1_8081_reached.png)           |           ![hw2_8082_reached.png](images%2Fhw2_8082_reached.png)           |
| Из пода hworld-1 | ![watch_hw1_hw1_curl_reached.png](images%2Fwatch_hw1_hw1_curl_reached.png) | ![watch_hw1_hw2_curl_reached.png](images%2Fwatch_hw1_hw2_curl_reached.png) |
| Из пода hworld-2 | ![watch_hw2_hw1_curl_reached.png](images%2Fwatch_hw2_hw1_curl_reached.png) | ![watch_hw2_hw2_curl_reached.png](images%2Fwatch_hw2_hw2_curl_reached.png) |

Всесторонняя доступность подов обусловлена тем, что на данный момент не существует ни одного правила,
применяемого к данным подам:
````bash
$ kubectl get networkpolicy -A
No resources found in default namespace.

$ kubectl get globalnetworkpolicy -A
No resources found
````

Установим настройки доступа к подам.

Рекомендуемой практикой является установить запрет на всё соединения и уже потом, по мере необходимости, разрешать
необходимые действия.

Так и поступим, изначально [запретив весь входящий трафик](./newNetworkPolicies/default-ingress-deny-all-pods-np.yaml)
для всех подов в пространстве имен `ns-1`:
````yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-all
  namespace: ns-1
spec:
  podSelector: {}
  ingress: []
````

````bash
$ kubectl apply -f default-ingress-deny-all-pods-np.yaml 
networkpolicy.networking.k8s.io/default-ingress-deny-all-pods created
````

Проверим доступность подов:

|                  |                                   Hello world 1                                    |                               Hello world 2                                |
|:-----------------|:----------------------------------------------------------------------------------:|:--------------------------------------------------------------------------:|
| Через внешний IP |          ![hw1_30001_not_reached.png](images%2Fhw1_30001_not_reached.png)          |          ![hw2_30002_reached.png](images%2Fhw2_30002_reached.png)          |
| Через localhost  |               ![hw1_8081_reached.png](images%2Fhw1_8081_reached.png)               |           ![hw2_8082_reached.png](images%2Fhw2_8082_reached.png)           |
| Из пода hworld-1 | ![watch_hw1_hw1_curl_not_reached.png](images%2Fwatch_hw1_hw1_curl_not_reached.png) | ![watch_hw1_hw2_curl_reached.png](images%2Fwatch_hw1_hw2_curl_reached.png) |
| Из пода hworld-2 | ![watch_hw2_hw1_curl_not_reached.png](images%2Fwatch_hw2_hw1_curl_not_reached.png) | ![watch_hw2_hw2_curl_reached.png](images%2Fwatch_hw2_hw2_curl_reached.png) |

Как видим, после применения к входящему трафику подов сетевой политики, запрещающей все входящие соединения,
под `hworld-1` стал недоступен (хотя доступ по перенаправленному на `localhost` порту `8081` почему-то
продолжает работать).

Удалим наложенную сетевую политику для входящего трафика и применим для всех подов пространства имен `ns-1` полный запрет
на [исходящий трафик](./newNetworkPolicies/default-egress-deny-all-pods-np.yaml):
````bash
$ kubectl delete networkpolicies default-ingress-deny-all-pods -n ns-1
networkpolicy.networking.k8s.io "default-ingress-deny-all-pods" deleted

$ kubectl apply -f default-egress-deny-all-pods-np.yaml
networkpolicy.networking.k8s.io/default-egress-deny-all-pods created
````

Проверяем доступность подов:

|                  |                                   Hello world 1                                    |                                   Hello world 2                                    |
|:-----------------|:----------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------:|
| Через внешний IP |              ![hw1_30001_reached.png](images%2Fhw1_30001_reached.png)              |              ![hw2_30002_reached.png](images%2Fhw2_30002_reached.png)              |
| Через localhost  |               ![hw1_8081_reached.png](images%2Fhw1_8081_reached.png)               |              ![hw2_8082_reached.png](images%2Fhw2_8082_reached.png)                |
| Из пода hworld-1 | ![watch_hw1_hw1_curl_not_reached.png](images%2Fwatch_hw1_hw1_curl_not_reached.png) | ![watch_hw1_hw2_curl_not_reached.png](images%2Fwatch_hw1_hw2_curl_not_reached.png) |
| Из пода hworld-2 |    ![watch_hw2_hw1_curl_reached.png](images%2Fwatch_hw2_hw1_curl_reached.png)      |     ![watch_hw2_hw2_curl_reached.png](images%2Fwatch_hw2_hw2_curl_reached.png)     |

Как видим, в случае запрета исходящего трафика для всех подов пространства имен `ns-1`, любая попытка пода `hworld-1`,
находящегося в этом пространстве имён, получить данные заканчивается неудачей.

Теперь наложим для всех подов пространства имен `ns-1` полный запрет и на
[входящий](./newNetworkPolicies/default-ingress-deny-all-pods-np.yaml) и на
[исходящий](./newNetworkPolicies/default-egress-deny-all-pods-np.yaml) трафик:
````bash
$ kubectl apply -f default-ingress-deny-all-pods-np.yaml 
networkpolicy.networking.k8s.io/default-ingress-deny-all-pods created

$ kubectl apply -f default-egress-deny-all-pods-np.yaml 
networkpolicy.networking.k8s.io/default-egress-deny-all-pods created
````

Снова проверяем доступность подов:

|                  |                                   Hello world 1                                    |                                   Hello world 2                                    |
|:-----------------|:----------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------:|
| Через внешний IP |          ![hw1_30001_not_reached.png](images%2Fhw1_30001_not_reached.png)          |              ![hw2_30002_reached.png](images%2Fhw2_30002_reached.png)              |
| Через localhost  |               ![hw1_8081_reached.png](images%2Fhw1_8081_reached.png)               |               ![hw2_8082_reached.png](images%2Fhw2_8082_reached.png)               |
| Из пода hworld-1 | ![watch_hw1_hw1_curl_not_reached.png](images%2Fwatch_hw1_hw1_curl_not_reached.png) | ![watch_hw1_hw2_curl_not_reached.png](images%2Fwatch_hw1_hw2_curl_not_reached.png)|
| Из пода hworld-2 | ![watch_hw2_hw1_curl_not_reached.png](images%2Fwatch_hw2_hw1_curl_not_reached.png) |![watch_hw2_hw2_curl_reached.png](images%2Fwatch_hw2_hw2_curl_reached.png) |

Теперь видим, что ни изнутри пода `hworld-1` нельзя получить никакие данные, ни снаружи нельзя получить данные этого пода
(хотя доступ через проброшенный на `localhost` порт `8081` по-прежнему функционирует).

> Для корректности эксперимента всё же следует разрешать подам доступ к внутренней DNS-службе кластера, в противном случае
> соединения не устанавливаются по банальной причине - невозможность разрешить имена хостов:
> ````yaml
> egress:
>   - to:
>      - ipBlock:
>           cidr: 169.254.25.10/32
>     ports:
>      - protocol: UDP
>        port: 53
>      - protocol: TCP
>        port: 53
>````
> Где подсеть 169.254.25.10/32 - это [Link Local](https://kubernetes.io/docs/tasks/administer-cluster/ip-masq-agent/) кластера.
> 
> Также можно использовать не адрес этой подсети, а обращаться по метке служебных подов (к которым конечно же
> относится и DNS) - `kube-system`: 
> ````yaml
>  - to:
>    - namespaceSelector:
>        matchLabels:
>          name: kube-system
> ````

Теперь отменим наложенные политики:
````bash
$ kubectl delete networkpolicies default-ingress-deny-all-pods -n ns-1
networkpolicy.networking.k8s.io "default-ingress-deny-all-pods" deleted

$ kubectl delete networkpolicies default-egress-deny-all-pods -n ns-1
networkpolicy.networking.k8s.io "default-egress-deny-all-pods" deleted
````

Как видим, функциональность подов полностью восстановлена:

|                  |                               Hello world 1                                |                               Hello world 2                                |
|:-----------------|:--------------------------------------------------------------------------:|:--------------------------------------------------------------------------:|
| Через внешний IP |          ![hw1_30001_reached.png](images%2Fhw1_30001_reached.png)          |          ![hw2_30002_reached.png](images%2Fhw2_30002_reached.png)          |
| Через localhost  |           ![hw1_8081_reached.png](images%2Fhw1_8081_reached.png)           |           ![hw2_8082_reached.png](images%2Fhw2_8082_reached.png)           |
| Из пода hworld-1 | ![watch_hw1_hw1_curl_reached.png](images%2Fwatch_hw1_hw1_curl_reached.png) | ![watch_hw1_hw2_curl_reached.png](images%2Fwatch_hw1_hw2_curl_reached.png) |
| Из пода hworld-2 | ![watch_hw2_hw1_curl_reached.png](images%2Fwatch_hw2_hw1_curl_reached.png) | ![watch_hw2_hw2_curl_reached.png](images%2Fwatch_hw2_hw2_curl_reached.png) |

**Т.о. мы продемонстрировали действие сетевых политик, примененных к входящему (`ingress`) и исходящему (`egress`) трафику.**

Теперь настроим взаимодействие между подами более избирательно.

Для начала, [запретим весь входящий и исходящий трафик](./newNetworkPolicies/default-deny-all-ns-np.yaml) уже для обеих
пространств имен - `ns-1` и `ns-2`:
````bash
$ kubectl apply -f default-deny-all-ns-np.yaml
networkpolicy.networking.k8s.io/default-deny-all-ns1 created
networkpolicy.networking.k8s.io/default-deny-all-ns2 created
````

Как результат, доступа к подам нет (кроме как через проброшенные на `localhost` порты `8081` и `8082`):

|                  |                                   Hello world 1                                    |                                   Hello world 2                                    |
|:-----------------|:----------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------:|
| Через внешний IP |          ![hw1_30001_not_reached.png](images%2Fhw1_30001_not_reached.png)          |          ![hw2_30002_not_reached.png](images%2Fhw2_30002_not_reached.png)          |
| Через localhost  |               ![hw1_8081_reached.png](images%2Fhw1_8081_reached.png)               |               ![hw2_8082_reached.png](images%2Fhw2_8082_reached.png)               |
| Из пода hworld-1 | ![watch_hw1_hw1_curl_not_reached.png](images%2Fwatch_hw1_hw1_curl_not_reached.png) | ![watch_hw1_hw2_curl_not_reached.png](images%2Fwatch_hw1_hw2_curl_not_reached.png) |
| Из пода hworld-2 | ![watch_hw2_hw1_curl_not_reached.png](images%2Fwatch_hw2_hw1_curl_not_reached.png) | ![watch_hw2_hw2_curl_not_reached.png](images%2Fwatch_hw2_hw2_curl_not_reached.png) |

1. Pазрешаем
   [поду `hworld-1` создавать исходящие соединения с подом `hworld-2` по порту 80](./newNetworkPolicies/allow-hw1-eg-hw2-np.yaml):

````bash
$ kubectl apply -f allow-hw1-eg-hw2-np.yaml 
networkpolicy.networking.k8s.io/allow-hw1-eg-hw2 created
````

Проверям доступ, изменений не произошло - связи между подами нет:

|                  |                                   Hello world 1                                    |                                   Hello world 2                                    |
|:-----------------|:----------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------:|
| Через внешний IP |          ![hw1_30001_not_reached.png](images%2Fhw1_30001_not_reached.png)          |          ![hw2_30002_not_reached.png](images%2Fhw2_30002_not_reached.png)          |
| Через localhost  |               ![hw1_8081_reached.png](images%2Fhw1_8081_reached.png)               |               ![hw2_8082_reached.png](images%2Fhw2_8082_reached.png)               |
| Из пода hworld-1 | ![watch_hw1_hw1_curl_not_reached.png](images%2Fwatch_hw1_hw1_curl_not_reached.png) | ![watch_hw1_hw2_curl_not_reached.png](images%2Fwatch_hw1_hw2_curl_not_reached.png) |
| Из пода hworld-2 | ![watch_hw2_hw1_curl_not_reached.png](images%2Fwatch_hw2_hw1_curl_not_reached.png) | ![watch_hw2_hw2_curl_not_reached.png](images%2Fwatch_hw2_hw2_curl_not_reached.png) |

Этого и следовало ожидать, поскольку для пода `hworld-1` нет политик, разрешающих соединение:

![allow-hw1-eg-hw2.jpg](images%2Fallow-hw1-eg-hw2.jpg)

2. Теперь разрешим
   [поду `hworld-2` принимать входящие соединения от пода `hworld-1` по порту 80](./newNetworkPolicies/allow-hw2-in-hw1-np.yaml):
````bash
$ kubectl apply -f allow-hw2-in-hw1-np.yaml
networkpolicy.networking.k8s.io/allow-hw2-in-hw1 created
````

Проверям доступ, как видим, под `hworld-1` получил возможность подключаться к поду `hworld-2`:

|                  |                                   Hello world 1                                    |                                   Hello world 2                                    |
|:-----------------|:----------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------:|
| Через внешний IP |          ![hw1_30001_not_reached.png](images%2Fhw1_30001_not_reached.png)          |          ![hw2_30002_not_reached.png](images%2Fhw2_30002_not_reached.png)          |
| Через localhost  |               ![hw1_8081_reached.png](images%2Fhw1_8081_reached.png)               |               ![hw2_8082_reached.png](images%2Fhw2_8082_reached.png)               |
| Из пода hworld-1 | ![watch_hw1_hw1_curl_not_reached.png](images%2Fwatch_hw1_hw1_curl_not_reached.png) |     ![watch_hw1_hw2_curl_reached.png](images%2Fwatch_hw1_hw2_curl_reached.png)     |
| Из пода hworld-2 | ![watch_hw2_hw1_curl_not_reached.png](images%2Fwatch_hw2_hw1_curl_not_reached.png) | ![watch_hw2_hw2_curl_not_reached.png](images%2Fwatch_hw2_hw2_curl_not_reached.png) |

Но при этом доступ извне кластера к подам отсутствует (кроме проброшенных на `localhost` портов `8081` и `8082`):

![allow-hw2-in-hw1.jpg](images%2Fallow-hw2-in-hw1.jpg)

> Обращаем внимание, что открывать приходится не порт `8082`, который является портом, с которым
> [сервис](./infrastructure/playbooks/templates/back-and-front/deploy-frontend-2.yaml) экспонирует приложение,
> а порт `80`, который прослушивается самим
> [приложением](./infrastructure/playbooks/templates/back-and-front/deploy-frontend-2.yaml).
> По-видимому, это связано с механизмом применения сетевых политик, когда политика вступает в силу где-то между
> деплойментом и экспонирующим его сервисом и если соответствующего разрешения нет, то связь между деплойментом и сервисом
> отсутствует.

3. Теперь разрешим
[поду `hworld-2` создавать исходящие соединения с подом `hworld-1` по порту `8082`](./newNetworkPolicies/allow-hw2-eg-hw1-np.yaml):
````bash
$ kubectl apply -f allow-hw2-eg-hw1-np.yaml 
networkpolicy.networking.k8s.io/allow-hw2-eg-hw1 created
````

Изменений, как и ожидалось нет - принимать входящие соединения от пода `hworld-2` поду `hworld-1` не разрешено:

![allow_hw2-eg-hw1.jpg](images%2Fallow_hw2-eg-hw1.jpg)

4. Разрешим
[поду `hworld-1` принимать входящие соединения от пода `hworld-2` по порту `8082`](./newNetworkPolicies/allow-hw1-in-hw2-np.yaml):
````bash
$ kubectl apply -f allow-hw1-in-hw2-np.yaml 
networkpolicy.networking.k8s.io/allow-hw1-in-hw2 created
````

Проверям доступ и видим, что под `hworld-2` получил возможность подключаться к поду `hworld-1`:

|                  |                                   Hello world 1                                    |                                   Hello world 2                                    |
|:-----------------|:----------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------:|
| Через внешний IP |          ![hw1_30001_not_reached.png](images%2Fhw1_30001_not_reached.png)          |          ![hw2_30002_not_reached.png](images%2Fhw2_30002_not_reached.png)          |
| Через localhost  |               ![hw1_8081_reached.png](images%2Fhw1_8081_reached.png)               |               ![hw2_8082_reached.png](images%2Fhw2_8082_reached.png)               |
| Из пода hworld-1 | ![watch_hw1_hw1_curl_not_reached.png](images%2Fwatch_hw1_hw1_curl_not_reached.png) |     ![watch_hw1_hw2_curl_reached.png](images%2Fwatch_hw1_hw2_curl_reached.png)     |
| Из пода hworld-2 | ![watch_hw2_hw1_curl_reached.png](images%2Fwatch_hw2_hw1_curl_reached.png) | ![watch_hw2_hw2_curl_not_reached.png](images%2Fwatch_hw2_hw2_curl_not_reached.png) |

Но как и ожидалось, доступ извне кластера к подам отсутствует (кроме проброшенных на `localhost` портов `8081` и `8082`):

![allow_hw1-in-hw2.jpg](images%2Fallow_hw1-in-hw2.jpg)

Двухсторонняя связь между подами `hworld-1` и `hworld-2` установлена. Нам осталось настроить связь пода `hworld-1` с внешним миром.

5. Для начала разрешим [поду `hworld-1` принимать входящие соединения извне](./newNetworkPolicies/allow-hw1-in-outside-np.yaml)
путем запрета соединения с любыми локальными подсетями, а остальным (т.е. нелокальным) разрешим доступ по 80 порту:
````yaml
  ingress:
    - from:
        - ipBlock:
            cidr: 0.0.0.0/0
            except:
              - 10.0.0.0/32
              - 100.64.0.0/32
              - 172.16.0.0/20
              - 192.168.0.0/16
      ports:
        - protocol: TCP
          port: 80
````

````bash
$ kubectl apply -f allow-hw1-in-outside-np.yaml
networkpolicy.networking.k8s.io/allow-hw1-in-outside created
````

Проверям доступ и видим, что под `hworld-1` стал доступен извне:

|                  |                                   Hello world 1                                    |                                   Hello world 2                                    |
|:-----------------|:----------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------:|
| Через внешний IP |              ![hw1_30001_reached.png](images%2Fhw1_30001_reached.png)              |          ![hw2_30002_not_reached.png](images%2Fhw2_30002_not_reached.png)          |
| Через localhost  |               ![hw1_8081_reached.png](images%2Fhw1_8081_reached.png)               |               ![hw2_8082_reached.png](images%2Fhw2_8082_reached.png)               |
| Из пода hworld-1 | ![watch_hw1_hw1_curl_not_reached.png](images%2Fwatch_hw1_hw1_curl_not_reached.png) |     ![watch_hw1_hw2_curl_reached.png](images%2Fwatch_hw1_hw2_curl_reached.png)     |
| Из пода hworld-2 |     ![watch_hw2_hw1_curl_reached.png](images%2Fwatch_hw2_hw1_curl_reached.png)     | ![watch_hw2_hw2_curl_not_reached.png](images%2Fwatch_hw2_hw2_curl_not_reached.png) |

6. Теперь разрешим поду `hworld-1` доступ к внешним сетям. Добьемся этого с помощью аналогичных правил, которые мы
только что применили для `ingress`-соединений, но [применив их к `egress`-соединениям](./newNetworkPolicies/allow-hw1-eg-outside-np.yaml):
````yaml
  egress:
    - to:
        - ipBlock:
            cidr: 0.0.0.0/0
            except:
              - 10.0.0.0/32
              - 100.64.0.0/32
              - 172.16.0.0/20
              - 192.168.0.0/16
````

````bash
$ kubectl apply -f allow-hw1-eg-outside-np.yaml 
networkpolicy.networking.k8s.io/allow-hw1-eg-outside created
````

Проверям доступ и видим, что поду `hworld-1` стали доступны внешние сети:

|                  |                               Hello world 1                                |                                   Hello world 2                                    |
|:-----------------|:--------------------------------------------------------------------------:|:----------------------------------------------------------------------------------:|
| Через внешний IP |          ![hw1_30001_reached.png](images%2Fhw1_30001_reached.png)          |          ![hw2_30002_not_reached.png](images%2Fhw2_30002_not_reached.png)          |
| Через localhost  |           ![hw1_8081_reached.png](images%2Fhw1_8081_reached.png)           |               ![hw2_8082_reached.png](images%2Fhw2_8082_reached.png)               |
| Из пода hworld-1 | ![watch_hw1_hw1_curl_reached.png](images%2Fwatch_hw1_hw1_curl_reached.png) |     ![watch_hw1_hw2_curl_reached.png](images%2Fwatch_hw1_hw2_curl_reached.png)     |
| Из пода hworld-2 | ![watch_hw2_hw1_curl_reached.png](images%2Fwatch_hw2_hw1_curl_reached.png) | ![watch_hw2_hw2_curl_not_reached.png](images%2Fwatch_hw2_hw2_curl_not_reached.png) |

> Доступность внешних сетей для пода `hworld-1` здесь мы определили косвенным образом, выполнив `curl`-запрос из
> этого пода к самому себе - запрос покинул под и вернулся к самому себе. Более чистым способом проверки
> доступности внешних сетей было бы выполнения запроса к какому-либо внешнему ресурсу.
 
Для дополнительной проверки обратимся, например, к ресурсу `www.google.com`:

| До применения разрешающей `egress`-политики                        |       После применения разрешающей `egress`-политики       |
|:-------------------------------------------------------------------|:----------------------------------------------------------:|
| ![hw1_google_not_reached.png](images%2Fhw1_google_not_reached.png) | ![hw1_google_reached.png](images%2Fhw1_google_reached.png) |

Как видим, политика, разрешающая доступ к внешним ресурсам, работает:

![allow-hw1-in-outside.jpg](images%2Fallow-hw1-in-outside.jpg)

Таким образом, мы добились желаемого - разрешили для пода `hworld_1` доступ в/из внешнего мира, а также и ко второму
поду `hworld_2`. Сам же под `hworld_2`, в свою очередь, имеет доступ только к поду `hworld_1`.

---

<details>
  <summary>Приложение 1 - Лекция</summary> 

По умолчанию под кластера доступен для всех остальных подов. Проверим это.

Создадим любое пространство имён:
````bash
$ kubectl create ns web-app              
namespace/web-app created
````

Развернем в этом пространстве имён любой под, например, простое веб-приложение
["Hello world!"](./infrastructure/playbooks/templates/back-and-front/deploy-frontend.yaml):
````bash
$ ansible-playbook -i inventory/hosts.yaml playbooks/deploy-apps.ansible.yaml

PLAY [Setup Kubernetes Cluster] ****************************************************************************************

TASK [Gathering Facts] *************************************************************************************************
ok: [cp1]

TASK [Upload manifest for frontend] ************************************************************************************
ok: [cp1]

TASK [Apply manifest for frontend] *************************************************************************************
changed: [cp1]

PLAY RECAP *************************************************************************************************************
cp1                        : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
````

Запускаем любой под, имеющий оболочку, например, уже имеющийся у нас
["Vault"](/run/media/oleg/Second/Netology/clokub-homeworks/14.5/vault/vault-pod.yaml):
````bash
$ kubectl apply -f vault-pod.yaml     
pod/14.2-netology-vault created
````

Подключимся к этому экземпляру Vault:
````bash
$ kubectl exec --stdin --tty 14.2-netology-vault -- sh
/ #
````

Изначально утилита `curl` в данном контейнере (ОС `Alpine Linux`) не установлена, установим её:
````bash
# cat /etc/os-release
NAME="Alpine Linux"
ID=alpine
VERSION_ID=3.14.8
PRETTY_NAME="Alpine Linux v3.14"
HOME_URL="https://alpinelinux.org/"
BUG_REPORT_URL="https://bugs.alpinelinux.org/"

# apk add curl
fetch https://dl-cdn.alpinelinux.org/alpine/v3.14/main/x86_64/APKINDEX.tar.gz
fetch https://dl-cdn.alpinelinux.org/alpine/v3.14/community/x86_64/APKINDEX.tar.gz
(1/4) Installing brotli-libs (1.0.9-r5)
(2/4) Installing nghttp2-libs (1.43.0-r0)
(3/4) Installing libcurl (7.79.1-r4)
(4/4) Installing curl (7.79.1-r4)
Executing busybox-1.33.1-r8.trigger
OK: 11 MiB in 23 packages
````

Проверим доступность работающего пода приложения "Hello world!":
````bash
# ping frontend-nodeport-svc.web-app.svc.cluster.local
PING frontend-nodeport-svc.web-app.svc.cluster.local (10.32.193.75): 56 data bytes
64 bytes from 10.32.193.75: seq=0 ttl=64 time=0.388 ms
64 bytes from 10.32.193.75: seq=1 ttl=64 time=0.161 ms
...
````

Под откликается. Получим веб-страницу "Hello world!":
````bash
/ # curl frontend-nodeport-svc.web-app.svc.cluster.local
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
  <title>Netology</title>
</head>
<body>
<h1>Hello world!</h1>
</body>
</html>
````

Веб-страница доступна. 

Т.о. мы проверили, что изначально поды одного пространства имён (`web-app`) доступны из подов другого пространства
имён (`default`) этого же кластера.


Пример определения `NetworkPolicy`:
````bash
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-ingress
spec:
  podSelector: {}
  policyTypes:
  - Ingress
````

Пример определения `ingress`-политики:
````bash
ingress:
  - from:
  - ipBlock:
      cidr: 172.17.0.0/16
      except:
      - 172.17.1.0/24
  - namespaceSelector:
      matchLabels:
        project: myproject
  - podSelector:
      matchLabels:
          role: frontend
  ports:
  - protocol: TCP
      port: 6379
````

Пример определения `egress`-политики:
````bash
egress:
- to:
- ipBlock:
    cidr: 10.0.0.0/24
ports:
- protocol: TCP
    port: 5978
````

Разъяснения можно найти в [дополнительных материалах к лекции](/run/media/oleg/Second/Netology/clokub-homeworks/14.5/additionalMaterials/NetworkPolicy/readme.md).

</details>

---
