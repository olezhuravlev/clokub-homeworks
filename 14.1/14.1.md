# Домашнее задание к занятию "14.1 Создание и использование секретов"

## Задача 1: Работа с секретами через утилиту kubectl в установленном minikube

Выполните приведённые ниже команды в консоли, получите вывод команд. Сохраните
задачу 1 как справочный материал.

### Как создать секрет?

```
openssl genrsa -out cert.key 4096
openssl req -x509 -new -key cert.key -days 3650 -out cert.crt \
-subj '/C=RU/ST=Moscow/L=Moscow/CN=server.local'
kubectl create secret tls domain-cert --cert=certs/cert.crt --key=certs/cert.key
```

### Как просмотреть список секретов?

```
kubectl get secrets
kubectl get secret
```

### Как просмотреть секрет?

```
kubectl get secret domain-cert
kubectl describe secret domain-cert
```

### Как получить информацию в формате YAML и/или JSON?

```
kubectl get secret domain-cert -o yaml
kubectl get secret domain-cert -o json
```

### Как выгрузить секрет и сохранить его в файл?

```
kubectl get secrets -o json > secrets.json
kubectl get secret domain-cert -o yaml > domain-cert.yml
```

### Как удалить секрет?

```
kubectl delete secret domain-cert
```

### Как загрузить секрет из файла?

```
kubectl apply -f domain-cert.yml
```

## Задача 2 (*): Работа с секретами внутри модуля

Выберите любимый образ контейнера, подключите секреты и проверьте их доступность
как в виде переменных окружения, так и в виде примонтированного тома.

---

## Решение

### Предварительная подготовка - разворачивание кластера Kubernetes

С помощью команды `terraform apply -auto-approve`, примененной к [конфигурации Terraform](./terraform/main.tf)
подготовим виртуальную инфраструктуру:

![](./images/yc_vms_3.png)

Наполним нашу виртуальную инфраструктуру программным содержимым с помощью [конфигурации Ansible](./infrastructure/site.yaml).
Для разворачивания кластера Kubernetes [используем Kubespray](./infrastructure/playbooks/mount-cluster.ansible.yaml).

В демонстрационных целях в нашем кластере развёрнуто простейшее приложение "Hello world!":

![](images/dockerhub_hw.png)

Работающее приложение доступно по порту `30000`:

![](images/kuber_cluster_hw.png)

Кроме того, также в демонстрационных целях имеем развернутую панель управления Kubernetes-кластера:

![](images/kuber_dashboard.png)

<details>
  <summary>Полная инфраструктура нашего Kubernetes-кластера выглядит следующим образом:</summary>

````bash
$ kubectl get all,secret,pvc,pv,ep,sc,netpol,ingress -A --field-selector metadata.namespace!=kube-system -o wide --show-labels
NAMESPACE              NAME                                            READY   STATUS    RESTARTS      AGE   IP               NODE    NOMINATED NODE   READINESS GATES   LABELS
default                pod/frontend-594db95f8d-rxqlc                   1/1     Running   2 (18m ago)   30m   10.200.104.12    node2   <none>           <none>            app=web-news,component=frontend,pod-template-hash=594db95f8d
default                pod/frontend-594db95f8d-zq8qx                   1/1     Running   2 (19m ago)   30m   10.200.166.135   node1   <none>           <none>            app=web-news,component=frontend,pod-template-hash=594db95f8d
default                pod/nfs-server-nfs-server-provisioner-0         1/1     Running   2 (18m ago)   31m   10.200.104.9     node2   <none>           <none>            app=nfs-server-provisioner,chart=nfs-server-provisioner-1.1.3,controller-revision-hash=nfs-server-nfs-server-provisioner-64bd6d7f65,heritage=Helm,release=nfs-server,statefulset.kubernetes.io/pod-name=nfs-server-nfs-server-provisioner-0
kubernetes-dashboard   pod/dashboard-metrics-scraper-8c47d4b5d-hjzvq   1/1     Running   2 (19m ago)   31m   10.200.166.136   node1   <none>           <none>            k8s-app=dashboard-metrics-scraper,pod-template-hash=8c47d4b5d
kubernetes-dashboard   pod/kubernetes-dashboard-6c75475678-phbqw       1/1     Running   3 (17m ago)   31m   10.200.104.10    node2   <none>           <none>            k8s-app=kubernetes-dashboard,pod-template-hash=6c75475678

NAMESPACE              NAME                                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                                                                                                     AGE   SELECTOR                                        LABELS
default                service/frontend-nodeport-svc               NodePort    10.32.212.151   <none>        80:30000/TCP                                                                                                30m   app=web-news,component=frontend                 app=web-news,component=frontend
default                service/kubernetes                          ClusterIP   10.32.0.1       <none>        443/TCP                                                                                                     38m   <none>                                          component=apiserver,provider=kubernetes
default                service/nfs-server-nfs-server-provisioner   ClusterIP   10.32.172.74    <none>        2049/TCP,2049/UDP,32803/TCP,32803/UDP,20048/TCP,20048/UDP,875/TCP,875/UDP,111/TCP,111/UDP,662/TCP,662/UDP   31m   app=nfs-server-provisioner,release=nfs-server   app.kubernetes.io/managed-by=Helm,app=nfs-server-provisioner,chart=nfs-server-provisioner-1.1.3,heritage=Helm,release=nfs-server
kubernetes-dashboard   service/dashboard-metrics-scraper           ClusterIP   10.32.157.8     <none>        8000/TCP                                                                                                    31m   k8s-app=dashboard-metrics-scraper               k8s-app=dashboard-metrics-scraper
kubernetes-dashboard   service/kubernetes-dashboard                ClusterIP   10.32.74.67     <none>        443/TCP                                                                                                     31m   k8s-app=kubernetes-dashboard                    k8s-app=kubernetes-dashboard

NAMESPACE              NAME                                        READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS                  IMAGES                                SELECTOR                            LABELS
default                deployment.apps/frontend                    2/2     2            2           30m   frontend                    olezhuravlev/hello-world:1.0.0        app=web-news,component=frontend     app=web-news,component=frontend
kubernetes-dashboard   deployment.apps/dashboard-metrics-scraper   1/1     1            1           31m   dashboard-metrics-scraper   kubernetesui/metrics-scraper:v1.0.8   k8s-app=dashboard-metrics-scraper   k8s-app=dashboard-metrics-scraper
kubernetes-dashboard   deployment.apps/kubernetes-dashboard        1/1     1            1           31m   kubernetes-dashboard        kubernetesui/dashboard:v2.6.1         k8s-app=kubernetes-dashboard        k8s-app=kubernetes-dashboard

NAMESPACE              NAME                                                  DESIRED   CURRENT   READY   AGE   CONTAINERS                  IMAGES                                SELECTOR                                                        LABELS
default                replicaset.apps/frontend-594db95f8d                   2         2         2       30m   frontend                    olezhuravlev/hello-world:1.0.0        app=web-news,component=frontend,pod-template-hash=594db95f8d    app=web-news,component=frontend,pod-template-hash=594db95f8d
kubernetes-dashboard   replicaset.apps/dashboard-metrics-scraper-8c47d4b5d   1         1         1       31m   dashboard-metrics-scraper   kubernetesui/metrics-scraper:v1.0.8   k8s-app=dashboard-metrics-scraper,pod-template-hash=8c47d4b5d   k8s-app=dashboard-metrics-scraper,pod-template-hash=8c47d4b5d
kubernetes-dashboard   replicaset.apps/kubernetes-dashboard-6c75475678       1         1         1       31m   kubernetes-dashboard        kubernetesui/dashboard:v2.6.1         k8s-app=kubernetes-dashboard,pod-template-hash=6c75475678       k8s-app=kubernetes-dashboard,pod-template-hash=6c75475678

NAMESPACE   NAME                                                 READY   AGE   CONTAINERS               IMAGES                                                LABELS
default     statefulset.apps/nfs-server-nfs-server-provisioner   1/1     31m   nfs-server-provisioner   quay.io/kubernetes_incubator/nfs-provisioner:v2.3.0   app.kubernetes.io/managed-by=Helm,app=nfs-server-provisioner,chart=nfs-server-provisioner-1.1.3,heritage=Helm,release=nfs-server

NAMESPACE              NAME                                      TYPE                 DATA   AGE     LABELS
default                secret/sh.helm.release.v1.nfs-server.v1   helm.sh/release.v1   1      31m     modifiedAt=1668318687,name=nfs-server,owner=helm,status=deployed,version=1
kubernetes-dashboard   secret/kubernetes-dashboard-certs         Opaque               0      31m     k8s-app=kubernetes-dashboard
kubernetes-dashboard   secret/kubernetes-dashboard-csrf          Opaque               1      31m     k8s-app=kubernetes-dashboard
kubernetes-dashboard   secret/kubernetes-dashboard-key-holder    Opaque               2      31m     <none>

NAMESPACE              NAME                                                        ENDPOINTS                                                          AGE   LABELS
default                endpoints/cluster.local-nfs-server-nfs-server-provisioner   <none>                                                             30m   <none>
default                endpoints/frontend-nodeport-svc                             10.200.104.12:80,10.200.166.135:80                                 30m   app=web-news,component=frontend
default                endpoints/kubernetes                                        10.240.0.11:6443                                                   38m   endpointslice.kubernetes.io/skip-mirror=true
default                endpoints/nfs-server-nfs-server-provisioner                 10.200.104.9:20048,10.200.104.9:662,10.200.104.9:111 + 9 more...   31m   app.kubernetes.io/managed-by=Helm,app=nfs-server-provisioner,chart=nfs-server-provisioner-1.1.3,heritage=Helm,release=nfs-server
kubernetes-dashboard   endpoints/dashboard-metrics-scraper                         10.200.166.136:8000                                                31m   k8s-app=dashboard-metrics-scraper
kubernetes-dashboard   endpoints/kubernetes-dashboard                              10.200.104.10:8443                                                 31m   k8s-app=kubernetes-dashboard

NAMESPACE   NAME                              PROVISIONER                                       RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE   LABELS
            storageclass.storage.k8s.io/nfs   cluster.local/nfs-server-nfs-server-provisioner   Delete          Immediate           true                   31m   app.kubernetes.io/managed-by=Helm,app=nfs-server-provisioner,chart=nfs-server-provisioner-1.1.3,heritage=Helm,release=nfs-server
````
</details>

![](images/kuber_cluster_all.png)

На этом разворачивание Kubernetes-кластера завершено.

---

### Задача 1 - Создание секрета

Генерация файла ключа `cert.key`:
````bash
$ openssl genrsa -out cert.key 4096
Generating RSA private key, 4096 bit long modulus (2 primes)
................................................................................................++++
.........................................................................++++
e is 65537 (0x010001)
````

Создание сертификата, имеющего структуру `x509` и сроком на 10 лет в виде файла `cert.crt`:
````bash
$ openssl req -x509 -new -key cert.key -days 3650 -out cert.crt -subj '/C=RU/ST=Novosibirsk/L=Novosibirsk/CN=server.local'
````

Добавление секрета в кластер с использованием имеющихся ключа и сертификата:
````bash
$ kubectl create secret tls domain-cert --cert=cert.crt --key=cert.key
secret/domain-cert created
````

Получим список имеющихся секретов принадлежащих пространству имен `default`:
````bash
$ kubectl get secrets
NAME                               TYPE                 DATA   AGE
domain-cert                        kubernetes.io/tls    2      8s
sh.helm.release.v1.nfs-server.v1   helm.sh/release.v1   1      21m
````

> Именования ресурсов можно использовать как во множественном, так и в единственном числе - `kubectl get secrets`
> или `kubectl get secret` дадут одинаковый результат.

Получим описание секрета `domain-cert`, расположенного в дефолтном пространстве имен:
````bash
$ kubectl describe secret domain-cert
Name:         domain-cert
Namespace:    default
Labels:       <none>
Annotations:  <none>

Type:  kubernetes.io/tls

Data
====
tls.crt:  1968 bytes
tls.key:  3243 bytes
````

Получим описание секрета `domain-cert` в формате `yaml`:
````bash
$ kubectl get secret domain-cert -o yaml
apiVersion: v1
data:
  tls.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0...
  tls.key: LS0tLS1CRUdJTiBSU0EgUFJJVkFURSB...
kind: Secret
metadata:
  creationTimestamp: "2022-11-13T06:13:16Z"
  name: domain-cert
  namespace: default
  resourceVersion: "4452"
  uid: 53108a41-aa7b-48d7-a639-2d1ebd919399
type: kubernetes.io/tls
````

Получим описание секрета `domain-cert` в формате `json`:
````bash
$ kubectl get secret domain-cert -o json
{
    "apiVersion": "v1",
    "data": {
        "tls.crt": "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0...",
        "tls.key": "LS0tLS1CRUdJTiBSU0EgUFJJVkFURSB..."
    },
    "kind": "Secret",
    "metadata": {
        "creationTimestamp": "2022-11-13T06:13:16Z",
        "name": "domain-cert",
        "namespace": "default",
        "resourceVersion": "4452",
        "uid": "53108a41-aa7b-48d7-a639-2d1ebd919399"
    },
    "type": "kubernetes.io/tls"
}
````

> Здесь следует обратить внимание, что значения ключей `tls.crt` и `tls.key` не являются непосредственно значением
> сертификата и ключа к нему - это их представление, закодированное алгоритмом `base64`, позволяющим представлять любые
> данные в виде только 64 символов ASCII. Мы легко можем убедиться в этом дешифровав значения этих ключей:
> ````bash
> $ echo "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0..." | base64 -d
> -----BEGIN CERTIFICATE-----
> MIIFgTCCA2mgAwIBAgIUJW8ndpGJhU7pjchNKb1sGbM1p1AwDQYJKoZIhvcNAQEL
> ...
> Z6TDyDhGbgtw0dfy9TzFnOwYfESP
> -----END CERTIFICATE-----
> ````
>
> ````bash
> $ echo "LS0tLS1CRUdJTiBSU0EgUFJJVkFURSB..." | base64 -d
> -----BEGIN RSA PRIVATE KEY-----
> MIIJKAIBAAKCAgEAnSHpSUI4Ta/mGke+pmkHHosUrj7DlGaMnF3iSPcopR31hrKv
> ...
> 1jKj+QOwRvycRjjZqF9eBK2zXwovd6o9Vx9OVJ4mS6RUZHMRVe+sVmn6i4g=
> -----END RSA PRIVATE KEY-----
> ````

Если завершить команду инструкцией `> ИмяФайла` можно направить вывод команды вместо `stdout` в файл:
````bash
$ kubectl get secrets -o json > secrets.json
$ kubectl get secret domain-cert -o yaml > domain-cert.yml
````

Удаление секрета из кластера:
````bash
$ kubectl get secrets
NAME                               TYPE                 DATA   AGE
domain-cert                        kubernetes.io/tls    2      2m15s
sh.helm.release.v1.nfs-server.v1   helm.sh/release.v1   1      24m

$ kubectl delete secret domain-cert
secret "domain-cert" deleted

$ kubectl get secrets
NAME                               TYPE                 DATA   AGE
sh.helm.release.v1.nfs-server.v1   helm.sh/release.v1   1      24m
````
Как видим, секрет был удалён из кластера.

Теперь загрузим секрет в кластер, воспользовавшись его файловым представлением, выгруженным ранее:
````bash
$ kubectl apply -f domain-cert.yml
secret/domain-cert created

$ kubectl get secrets
NAME                               TYPE                 DATA   AGE
domain-cert                        kubernetes.io/tls    2      4s
sh.helm.release.v1.nfs-server.v1   helm.sh/release.v1   1      25m

$ kubectl describe secret domain-cert
Name:         domain-cert
Namespace:    default
Labels:       <none>
Annotations:  <none>

Type:  kubernetes.io/tls

Data
====
tls.crt:  1968 bytes
tls.key:  3243 bytes
````

Как видим, секрет был загружен из файла в Kubernetes-кластер.

---

### Задача 2 - Использование секрета в модуле


#### Доступ к секрету через переменные окружения

Для объявления содержимого секрета в переменных окружения модуля нам необходимо знать ключи секрета.
Для их получения извлечем описание секрета:
````bash
$ kubectl describe secret domain-cert
Name:         domain-cert
Namespace:    default
Labels:       <none>
Annotations:  <none>

Type:  kubernetes.io/tls

Data
====
tls.crt:  1968 bytes
tls.key:  3243 bytes
````

Здесь секрет содержит два ключа - `tls.crt` и `tls.key`.

> Значения ключей секрета можно получить и напрямую из их [определения в секции "data"](./secrets/domain-cert.yml).

Объявим в [определении деплоймента](./infrastructure/playbooks/templates/back-and-front/deploy-frontend-env-secret.yaml)
использование секрета в виде смонтированных в контейнере переменных окружения, например,
с именами `SECRET_CRT` и `SECRET_KEY`:
````bash
containers:
- name: frontend
  image: olezhuravlev/hello-world:1.0.0
  ports:
  - name: frontend-port
    containerPort: 80
    protocol: TCP
  env:
    - name: SECRET_CRT
      valueFrom:
        secretKeyRef:
          name: domain-cert
          key: tls.crt
          optional: false
    - name: SECRET_KEY
      valueFrom:
        secretKeyRef:
          name: domain-cert
          key: tls.key
          optional: false
````

Применим новое [определение деплоймента](./infrastructure/playbooks/templates/back-and-front/deploy-frontend-env-secret.yaml):
````bash
$ kubectl apply -f playbooks/templates/back-and-front/deploy-frontend-env-secret.yaml  
deployment.apps/frontend configured
service/frontend-nodeport-svc unchanged
````

После того, как кластер обновится, получим список имеющихся подов:
````bash
$ kubectl get po -o wide                                                             
NAME                                  READY   STATUS    RESTARTS       AGE    IP               NODE    NOMINATED NODE   READINESS GATES
frontend-55f4f56f89-gz5z9             1/1     Running   0              66s    10.200.166.140   node1   <none>           <none>
frontend-55f4f56f89-42v6l             1/1     Running   0              64s    10.200.104.15    node2   <none>           <none>
nfs-server-nfs-server-provisioner-0   1/1     Running   2 (143m ago)   155m   10.200.104.9     node2   <none>           <none>
````

Подключимся к любому поду, в котором запущен наш деплоймент и получим значения объявленных переменных окружения:
````bash
$ kubectl exec --stdin --tty frontend-55f4f56f89-gz5z9 -- /bin/bash

root@frontend-55f4f56f89-gz5z9:/# echo $SECRET_CRT
-----BEGIN CERTIFICATE-----
MIIFgTCCA2mgAwIBAgIUJW8ndpGJhU7pjchNKb1sGbM1p1AwDQYJKoZIhvcNAQEL
...
-----END CERTIFICATE-----
root@frontend-55f4f56f89-gz5z9:/# echo $SECRET_KEY
-----BEGIN RSA PRIVATE KEY-----
MIIJKAIBAAKCAgEAnSHpSUI4Ta/mGke+pmkHHosUrj7DlGaMnF3iSPcopR31hrKv
...
-----END RSA PRIVATE KEY-----
root@frontend-55f4f56f89-gz5z9:/# 
````

Т.о., обратившись к значениям объявленных переменных окружения `SECRET_CRT` и `SECRET_KEY`, мы получили данные
сертификата и ключа.


#### Доступ к секрету через смонтированный том

Получим еще раз список секретов, имеющихся в пространстве имен `default`:
````bash
$ kubectl get secrets                                              
NAME                               TYPE                 DATA   AGE
domain-cert                        kubernetes.io/tls    2      83m
sh.helm.release.v1.nfs-server.v1   helm.sh/release.v1   1      117m
````

Объявим в [определении деплоймента](./infrastructure/playbooks/templates/back-and-front/deploy-frontend-mounted-secret.yaml)
использование секрета в виде смонтированного в контейнере тома:
````bash
containers:
- name: frontend
  image: olezhuravlev/hello-world:1.0.0
  ports:
  - name: frontend-port
    containerPort: 80
    protocol: TCP
  volumeMounts:
    - name: my-secret-volume
      mountPath: "/mySecretVolumePath"
volumes:
  - name: my-secret-volume
    secret:
      secretName: domain-cert
````

Применим новое [определение деплоймента](./infrastructure/playbooks/templates/back-and-front/deploy-frontend-mounted-secret.yaml):
````bash
$ kubectl apply -f playbooks/templates/back-and-front/deploy-frontend-mounted-secret.yaml
deployment.apps/frontend configured
service/frontend-nodeport-svc unchanged
````

После того, как кластер обновится, получим список имеющихся подов:
````bash
$ kubectl get po -o wide
NAME                                  READY   STATUS    RESTARTS       AGE    IP               NODE    NOMINATED NODE   READINESS GATES
frontend-54f59c9967-9rkn8             1/1     Running   0              47s    10.200.166.139   node1   <none>           <none>
frontend-54f59c9967-5jbhf             1/1     Running   0              45s    10.200.104.14    node2   <none>           <none>
nfs-server-nfs-server-provisioner-0   1/1     Running   2 (125m ago)   137m   10.200.104.9     node2   <none>           <none>
````

Подключимся к любому поду, в котором запущен наш деплоймент и получим список содержимого смонтированного тома:
````bash
$ kubectl exec --stdin --tty frontend-54f59c9967-9rkn8 -- /bin/bash

root@frontend-54f59c9967-9rkn8:/# ls -l mySecretVolumePath/
total 0
lrwxrwxrwx 1 root root 14 Nov 13 08:08 tls.crt -> ..data/tls.crt
lrwxrwxrwx 1 root root 14 Nov 13 08:08 tls.key -> ..data/tls.key
````

Т.о., обратившись по смонтированному пути `mySecretVolumePath`, мы убедились, что файлы сертификата
и ключа к нему присутствуют в данной директории.

---
